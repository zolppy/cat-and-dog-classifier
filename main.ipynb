{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0_X4jbOscv4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models, utils, Input, Model\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPkPOkgMscv8"
      },
      "outputs": [],
      "source": [
        "# Define constants for image size, batch size, and epochs\n",
        "IMAGE_SIZE      = (180, 180)\n",
        "BATCH_SIZE      = 32\n",
        "EPOCHS          = 10\n",
        "TRANSFER_EPOCHS = 10\n",
        "DATASET_PATH    = 'Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOo4XzvOscv9"
      },
      "outputs": [],
      "source": [
        "# Download and unzip the cats and dogs dataset\n",
        "!wget -q https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "# Clean up unnecessary files and rename the directory\n",
        "!rm kagglecatsanddogs_5340.zip readme\\[1\\].txt CDLA-Permissive-2.0.pdf\n",
        "!mv PetImages Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg1XjKLXscv9"
      },
      "outputs": [],
      "source": [
        "# Create the training dataset from the directory, splitting 20% for validation\n",
        "train_ds = image_dataset_from_directory(\n",
        "    DATASET_PATH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69og3J8xscv-"
      },
      "outputs": [],
      "source": [
        "# Create the validation dataset from the directory\n",
        "val_ds = image_dataset_from_directory(\n",
        "    DATASET_PATH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ1mIVKPscv_"
      },
      "outputs": [],
      "source": [
        "# Get the number of classes from the training dataset\n",
        "num_classes = len(train_ds.class_names)\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5sL-WY2scwA"
      },
      "outputs": [],
      "source": [
        "# Define the custom CNN model architecture\n",
        "model = models.Sequential([\n",
        "    Input(shape=IMAGE_SIZE + (3,)),\n",
        "    layers.Rescaling(1./255), # Normalize pixel values to [0, 1]\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.2), # Add dropout for regularization\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax') # Output layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45d8JSLCscwB"
      },
      "outputs": [],
      "source": [
        "# Compile the model with Adam optimizer and sparse categorical crossentropy loss\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmHlQ1hPscwB"
      },
      "outputs": [],
      "source": [
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99NBeYlOscwC"
      },
      "outputs": [],
      "source": [
        "# Train the model and store the history\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzR5KK9JscwC"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation accuracy for the custom CNN\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"accuracy\"],     label=\"train_acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.legend()\n",
        "plt.title(\"Custom CNN Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional base from the first few layers of the trained model\n",
        "conv_base = models.Sequential()\n",
        "for layer in model.layers[:4]:  # Input, Rescaling, Conv2D, MaxPooling2D\n",
        "    conv_base.add(layer)\n",
        "\n",
        "# Freeze the convolutional base to prevent its weights from being updated\n",
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "qAsqhE_l4CEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a new model for transfer learning\n",
        "inputs = Input(shape=IMAGE_SIZE + (3,))\n",
        "x = conv_base(inputs, training=False) # Pass inputs through the frozen base\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(64, activation='relu')(x) # Add new trainable dense layers\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "transfer_model = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "X-OgdrG6_pv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the summary of the original model (to compare)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qlsyNkGe_t7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the transfer learning model\n",
        "transfer_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "CN_4rUTo_vcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the transfer learning model\n",
        "transfer_history = transfer_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=TRANSFER_EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "kOyexysU_xg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy for the transfer learning model\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(transfer_history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(transfer_history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.legend()\n",
        "plt.title(\"Transfer Learning Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HXiZfz8U_zZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}